"""
dart_langgraph.py â€” LangGraph ê¸°ë°˜ ì¬ë¬´ ë¶„ì„ íŒŒì´í”„ë¼ì¸ (ì‹¤í—˜ìš©, í˜„ì¬ ë¯¸ì‚¬ìš©)

[ì—­í• ]
  ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ ê¸°ì—…ëª…ì„ ì¶”ì¶œ(Gemini Flash) â†’ DARTì—ì„œ ì¬ë¬´ ë°ì´í„° ìˆ˜ì§‘
  â†’ ë¡œì»¬ íŒŒì¸íŠœë‹ ëª¨ë¸(Ollama)ë¡œ ë¶„ì„ â†’ ê²°ê³¼ ê²€ì¦ì˜ ë©€í‹°ìŠ¤í… ì›Œí¬í”Œë¡œìš°.

[íŒŒì´í”„ë¼ì¸ êµ¬ì¡°]
  company_extractor (Gemini Flash)
    â†’ ê¸°ì—…ëª… ì¶”ì¶œ + DART ì¬ë¬´ ë°ì´í„° ìˆ˜ì§‘ (fetch_financials.get_refined_financials)
  extractor (Ollama dart_model_v1)
    â†’ íŒŒì¸íŠœë‹ ëª¨ë¸ë¡œ 8ëŒ€ ì¬ë¬´ ì§€í‘œ ì¶”ì¶œ ë° JSON ìƒì„±
  validator
    â†’ ë§¤ì¶œì•¡ ëˆ„ë½, ë…¼ë¦¬ ì˜¤ë¥˜ ê²€ì¦ (ìµœëŒ€ 3íšŒ ì¬ì‹œë„)

[ì˜ì¡´]
  - fetch_financials.py (backend/src/tools/) â†’ get_refined_financials()
  - langchain_ollama, langchain_google_genai, langgraph
  - Ollamaì— dart_model_v1 ëª¨ë¸ì´ ë¡œì»¬ì— ë“±ë¡ë˜ì–´ ìˆì–´ì•¼ ì‹¤í–‰ ê°€ëŠ¥

[ë¹„ê³ ]
  ì„œë¹„ìŠ¤ ë©”ì¸ íë¦„ì—ì„œëŠ” í˜¸ì¶œë˜ì§€ ì•Šìœ¼ë©°, ë‹¨ë… ì‹¤í–‰(__main__)ìœ¼ë¡œ í…ŒìŠ¤íŠ¸í•˜ëŠ” ìš©ë„.
"""
import json
import re
import os
from typing import TypedDict, Optional
from langchain_ollama import ChatOllama
from langchain_google_genai import ChatGoogleGenerativeAI
from langgraph.graph import StateGraph, END
from fetch_financials import get_refined_financials
from dotenv import load_dotenv

load_dotenv()

# ==========================================
# 1. ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ë¶„ë¦¬
# ==========================================
# [ë¹„ì„œ] Gemini 1.5 Flash - ê¸°ì—…ëª… ì¶”ì¶œìš© (API ì‚¬ìš©)
llm_general = ChatGoogleGenerativeAI(
    model="gemini-1.5-flash",
    google_api_key=os.getenv("GOOGLE_API_KEY"),
    temperature=0
)

# [ë¶„ì„ê°€] ë¡œì»¬ íŒŒì¸íŠœë‹ ëª¨ë¸ - ì¬ë¬´ ë¶„ì„ìš© (Ollama ì‚¬ìš©)
llm_analyser = ChatOllama(model="dart_model_v1", temperature=0)

class GraphState(TypedDict):
    user_query: str
    company_name: Optional[str]
    raw_text: Optional[str]
    financial_data: Optional[dict]
    error_msg: Optional[str]
    retry_count: int

# ==========================================
# 2. ë…¸ë“œ ì •ì˜
# ==========================================

def company_extractor_node(state: GraphState):
    print("--- [NODE] ê¸°ì—…ëª… ì¶”ì¶œ (Gemini-Flash) ---")
    user_query = state["user_query"]
    
    # GeminiëŠ” ì§€ì‹œë¥¼ ë§¤ìš° ì˜ ë”°ë¦…ë‹ˆë‹¤.
    prompt = f"ë‹¤ìŒ ì§ˆë¬¸ì—ì„œ ê¸°ì—… ì´ë¦„ë§Œ í•œ ë‹¨ì–´ë¡œ ì¶”ì¶œí•´ì¤˜. ë‹¤ë¥¸ ë§ì€ ì ˆëŒ€ í•˜ì§€ ë§ˆ. ì—†ìœ¼ë©´ 'None'.\nì§ˆë¬¸: {user_query}"
    
    response = llm_general.invoke(prompt)
    # Gemini ì‘ë‹µì—ì„œ ê¸°ì—…ëª…ë§Œ ì •ì œ
    company_name = response.content.strip().split('\n')[0].replace('*', '')
    company_name = re.sub(r'[^\w\s]', '', company_name).split(' ')[0]
    
    print(f"ğŸ” ì¶”ì¶œëœ ê¸°ì—…ëª…: {company_name}")

    if company_name == "None" or not company_name:
        return {"error_msg": "ê¸°ì—…ëª…ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.", "company_name": "None"}

    # ì •ì œ íˆ´ í˜¸ì¶œ
    refined_dict = get_refined_financials(company_name, 2025)
    if not refined_dict:
        return {"company_name": company_name, "error_msg": "DART ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨"}

    return {
        "company_name": company_name,
        "raw_text": json.dumps(refined_dict, ensure_ascii=False, indent=2),
        "error_msg": None
    }

def extractor_node(state: GraphState):
    print(f"--- [NODE] ì¬ë¬´ ì§€í‘œ ì¶”ì¶œ (dart_model_v1) ---")
    raw_text = state["raw_text"]
    error_msg = state.get("error_msg")
    
    correction = f"\n\n[ë³´ì • ìš”ì²­]: {error_msg}" if error_msg else ""
    instruction = "ì œì‹œëœ ì¬ë¬´ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•µì‹¬ ì§€í‘œ 8ì¢…ì„ ì¶”ì¶œí•˜ê³  ì£¼ìš” ì¬ë¬´ ë¹„ìœ¨ì„ ë¶„ì„í•˜ì—¬ JSONìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”."
    input_data = f"{state['company_name']}ì˜ ì¬ë¬´ ë°ì´í„°: {raw_text}"

    # íŒŒì¸íŠœë‹ ì‹œ ì‚¬ìš©í–ˆë˜ í¬ë§· ê·¸ëŒ€ë¡œ ìœ ì§€
    prompt = f"### Instruction:\n{instruction}\n\n### Input:\n{input_data}{correction}\n\n### Response:\n"
    
    response = llm_analyser.invoke(prompt)
    
    try:
        json_match = re.search(r"\{.*\}", response.content, re.DOTALL)
        data = json.loads(json_match.group().replace("'", '"'))
        return {"financial_data": data, "retry_count": state["retry_count"] + 1}
    except:
        return {"error_msg": "JSON ìƒì„± ì‹¤íŒ¨", "retry_count": state["retry_count"] + 1}

def validator_node(state: GraphState):
    data = state["financial_data"]
    if not data: return {"error_msg": "ë°ì´í„° íŒŒì‹± ì—ëŸ¬"}
    
    # v1 ëª¨ë¸ì´ ë±‰ì€ í‚¤ê°’(financial_metrics)ì— ë§ì¶° ì²´í¬
    metrics = data.get("financial_metrics", {})
    rev = metrics.get("ë§¤ì¶œì•¡") or data.get("revenue") or 0
    pro = metrics.get("ì˜ì—…ì´ìµ") or data.get("profit") or 0
    
    if rev == 0: return {"error_msg": "ë§¤ì¶œì•¡ ëˆ„ë½"}
    if rev < pro: return {"error_msg": "ë§¤ì¶œì•¡ì´ ì˜ì—…ì´ìµë³´ë‹¤ ì‘ìŒ"}
    return {"error_msg": None}

# ==========================================
# 3. ê·¸ë˜í”„ êµ¬ì„±
# ==========================================

def route_after_extraction(state: GraphState):
    return "end" if state.get("error_msg") else "continue"

def should_continue(state: GraphState):
    return "end" if state["error_msg"] is None or state["retry_count"] >= 3 else "continue"

workflow = StateGraph(GraphState)
workflow.add_node("company_extractor", company_extractor_node)
workflow.add_node("extractor", extractor_node)
workflow.add_node("validator", validator_node)

workflow.set_entry_point("company_extractor")
workflow.add_conditional_edges("company_extractor", route_after_extraction, {"continue": "extractor", "end": END})
workflow.add_edge("extractor", "validator")
workflow.add_conditional_edges("validator", should_continue, {"continue": "extractor", "end": END})

app = workflow.compile()

if __name__ == "__main__":
    result = app.invoke({"user_query": "ì‚¼ì„±ì „ì ì´ë²ˆ ì‹¤ì  ë¶„ì„í•´ì¤˜", "retry_count": 0})
    print(f"\nâœ… ë¶„ì„ ê²°ê³¼:\n{json.dumps(result['financial_data'], indent=4, ensure_ascii=False)}")