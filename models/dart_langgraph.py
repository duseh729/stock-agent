import json
import re
from typing import TypedDict, Optional
from langchain_ollama import ChatOllama
from langgraph.graph import StateGraph, END

# 1. ìƒíƒœ ì •ì˜ (GraphState í™•ì¥)
class GraphState(TypedDict):
    user_query: str          # ì‚¬ìš©ìì˜ ì§ˆë¬¸ (ì˜ˆ: "ì‚¼ì„±ì „ì íˆ¬ìí• ë§Œí•´?")
    company_name: Optional[str] # ì¶”ì¶œëœ ê¸°ì—…ëª…
    raw_text: Optional[str]  # ê°€ì ¸ì˜¨ ê³µì‹œ í…ìŠ¤íŠ¸
    financial_data: Optional[dict]
    error_msg: Optional[str]
    retry_count: int

# 2. ëª¨ë¸ ì„¤ì •
llm = ChatOllama(model="dart_model_v1", temperature=0)

# 3. [ì‹ ê·œ] ê¸°ì—…ëª… ì¶”ì¶œ ë…¸ë“œ (company_extractor_node)
def company_extractor_node(state: GraphState):
    user_query = state["user_query"]
    
    prompt = f"""### Instruction:
ë‹¤ìŒ [ì‚¬ìš©ì ì§ˆë¬¸]ì—ì„œ ë¶„ì„ ëŒ€ìƒì¸ 'ê¸°ì—… ì´ë¦„'ë§Œ ì¶”ì¶œí•˜ë¼. 
ì¡°ì‚¬(ì€/ëŠ”/ì´/ê°€)ë¥¼ ì œì™¸í•˜ê³  ê¸°ì—… ì´ë¦„ë§Œ ë”± í•˜ë‚˜ ì¶œë ¥í•´. 
ê¸°ì—…ëª…ì´ ì—†ìœ¼ë©´ 'None'ì´ë¼ê³  ë‹µí•´.

[ì‚¬ìš©ì ì§ˆë¬¸]: {user_query}

### Response:
"""
    response = llm.invoke(prompt)
    company_name = response.content.strip().replace("'", "").replace('"', "")
    
    # ê°„ë‹¨í•œ ì •ì œ (ë§ˆì¹¨í‘œ ë“± ì œê±°)
    company_name = re.sub(r'[^\w\s]', '', company_name)
    
    print(f"ğŸ” ë‹¨ê³„ 1 [ê¸°ì—…ëª… ì¶”ì¶œ]: {company_name}")
    
    # ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ì—¬ê¸°ì„œ DART API ë“±ì„ í˜¸ì¶œí•´ raw_textë¥¼ ê°€ì ¸ì™€ì•¼ í•©ë‹ˆë‹¤.
    # ì¼ë‹¨ì€ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ë”ë¯¸ ë°ì´í„°ë¥¼ ë„£ì–´ì¤ë‹ˆë‹¤.
    dummy_text = f"({company_name})ëŠ” 2025ë…„ ë§¤ì¶œì•¡ 2ì¡° 5,000ì–µì›, ì˜ì—…ì´ìµ 3,000ì–µì›ì„ ê¸°ë¡í•˜ì˜€ë‹¤."
    
    return {
        "company_name": company_name,
        "raw_text": dummy_text
    }

# 4. ì¶”ì¶œ ë…¸ë“œ (extractor_node) - ê¸°ì¡´ ìœ ì§€ ë° í”„ë¡¬í”„íŠ¸ ë³´ê°•
def extractor_node(state: GraphState):
    raw_text = state["raw_text"]
    error_msg = state["error_msg"]
    retry_count = state.get("retry_count", 0)
    
    correction_prompt = ""
    if error_msg:
        correction_prompt = f"\n\n[ì´ì „ ì‹œë„ ì—ëŸ¬]: {error_msg}\nì£¼ì˜: ìë¦¿ìˆ˜ë¥¼ ë‹¤ì‹œ í™•ì¸í•˜ì„¸ìš” (1ì¡°=0 12ê°œ, 1000ì–µ=0 11ê°œ)."

    instruction = f"""ë‹¤ìŒ ê¸°ì—… ê³µì‹œ í…ìŠ¤íŠ¸ì—ì„œ ì£¼ìš” ì¬ë¬´ ì§€í‘œë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œí•´ì¤˜.
    
[ìë¦¿ìˆ˜ ê·œì¹™]
- 1ì¡°: 1,000,000,000,000 (0ì´ 12ê°œ)
- 1,000ì–µ: 100,000,000,000 (0ì´ 11ê°œ)

í…ìŠ¤íŠ¸: {raw_text}{correction_prompt}"""

    prompt = f"### Instruction:\n{instruction}\n\n### Response:\n"
    response = llm.invoke(prompt)
    content = response.content.strip()
    
    try:
        json_match = re.search(r"\{.*\}", content, re.DOTALL)
        data = json.loads(json_match.group().replace("'", '"')) if json_match else None
    except:
        data = None
        
    print(f"ğŸ“Š ë‹¨ê³„ 2 [ì§€í‘œ ì¶”ì¶œ ì‹œë„]: {retry_count + 1}íšŒì°¨")
    return {"financial_data": data, "retry_count": retry_count + 1}

# 5. ê²€ì¦ ë…¸ë“œ (validator_node) - ê¸°ì¡´ ìœ ì§€
def validator_node(state: GraphState):
    data = state["financial_data"]
    raw_text = state["raw_text"]
    
    if not data:
        return {"error_msg": "JSON í˜•ì‹ì„ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
    
    revenue = data.get("revenue", 0) or 0
    # 'ì¡°' ë‹¨ìœ„ ê²€ì¦ ì¶”ê°€
    if "ì¡°" in raw_text and revenue < 10**12:
        return {"error_msg": "í…ìŠ¤íŠ¸ì— 'ì¡°'ê°€ ìˆëŠ”ë° ê²°ê³¼ëŠ” 'ì–µ' ë‹¨ìœ„ì…ë‹ˆë‹¤. 0ì˜ ê°œìˆ˜ë¥¼ 12ê°œë¡œ ë§ì¶”ì„¸ìš”."}
    
    if revenue < data.get("profit", 0):
        return {"error_msg": "ë§¤ì¶œì•¡ì´ ì˜ì—…ì´ìµë³´ë‹¤ ì‘ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
    
    return {"error_msg": None}

# 6. ì¡°ê±´ë¶€ ì—ì§€ ë° ê·¸ë˜í”„ ë¹Œë“œ
def should_continue(state: GraphState):
    if state["error_msg"] is None or state["retry_count"] >= 3:
        return "end"
    return "continue"

workflow = StateGraph(GraphState)

# ë…¸ë“œ ì¶”ê°€
workflow.add_node("company_extractor", company_extractor_node)
workflow.add_node("extractor", extractor_node)
workflow.add_node("validator", validator_node)

# ì—°ê²° (company_extractor -> extractor -> validator)
workflow.set_entry_point("company_extractor")
workflow.add_edge("company_extractor", "extractor")
workflow.add_edge("extractor", "validator")

workflow.add_conditional_edges(
    "validator",
    should_continue,
    {"continue": "extractor", "end": END}
)

app = workflow.compile()

# 7. ì‹¤í–‰ë¶€
if __name__ == "__main__":
    query = "ì‚¼ì„±ì „ì ì´ë²ˆì— íˆ¬ìí• ë§Œ í•˜ëƒ? ì‹¤ì  ì¢€ ë´ì¤˜"
    
    initial_state = {
        "user_query": query,
        "company_name": None,
        "raw_text": None,
        "financial_data": None,
        "error_msg": None,
        "retry_count": 0
    }
    
    result = app.invoke(initial_state)
    
    print("\n" + "="*50)
    print(f"[ìµœì¢… ë¶„ì„ ëŒ€ìƒ ê¸°ì—…]: {result['company_name']}")
    print("[ì¶”ì¶œëœ ì¬ë¬´ ë°ì´í„°]")
    print(json.dumps(result["financial_data"], indent=4, ensure_ascii=False))
    print("="*50)